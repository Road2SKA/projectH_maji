{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# FloodMapper Inference Demo\n\nThis notebook demonstrates water/cloud classification using the WorldFloods UNet model\non a Sentinel-2 GeoTIFF tile.\n\n**Key features:**\n- Self-contained UNet implementation (no ml4floods dependency)\n- Loads pre-trained WF2_unet_rbgiswirs weights\n- **Interactive tile selection** - explore different regions using sliders or preset buttons\n- Visualizes RGB input and water/cloud prediction"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-05T13:37:22.584175Z",
     "iopub.status.busy": "2026-02-05T13:37:22.583997Z",
     "iopub.status.idle": "2026-02-05T13:37:23.788265Z",
     "shell.execute_reply": "2026-02-05T13:37:23.787776Z"
    }
   },
   "outputs": [],
   "source": "%matplotlib inline\n\nimport json\nfrom pathlib import Path\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport rasterio\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap\n\n# Check for GPU\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. UNet Architecture\n",
    "\n",
    "Standard 4-level encoder/decoder with skip connections.\n",
    "This matches the ml4floods UNet architecture exactly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-05T13:37:23.808673Z",
     "iopub.status.busy": "2026-02-05T13:37:23.808459Z",
     "iopub.status.idle": "2026-02-05T13:37:23.814101Z",
     "shell.execute_reply": "2026-02-05T13:37:23.813478Z"
    }
   },
   "outputs": [],
   "source": [
    "def _double_conv(in_ch: int, out_ch: int) -> nn.Sequential:\n",
    "    \"\"\"Two consecutive Conv2d-ReLU blocks.\"\"\"\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1),\n",
    "        nn.ReLU(inplace=True),\n",
    "    )\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    \"\"\"\n",
    "    4-level UNet for semantic segmentation.\n",
    "    \n",
    "    Architecture:\n",
    "        Encoder: 4 double-conv blocks with max pooling\n",
    "        Decoder: 3 upsampling + skip connection + double-conv blocks\n",
    "        Output: 1x1 conv to num_classes\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    in_channels : int\n",
    "        Number of input channels (e.g., 6 for bgriswirs bands).\n",
    "    num_classes : int\n",
    "        Number of output classes (2 for water/cloud binary heads).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels: int, num_classes: int):\n",
    "        super().__init__()\n",
    "        # Encoder\n",
    "        self.dconv_down1 = _double_conv(in_channels, 64)\n",
    "        self.dconv_down2 = _double_conv(64, 128)\n",
    "        self.dconv_down3 = _double_conv(128, 256)\n",
    "        self.dconv_down4 = _double_conv(256, 512)\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "        \n",
    "        # Decoder\n",
    "        self.dconv_up3 = _double_conv(256 + 512, 256)\n",
    "        self.dconv_up2 = _double_conv(128 + 256, 128)\n",
    "        self.dconv_up1 = _double_conv(64 + 128, 64)\n",
    "        \n",
    "        # Output\n",
    "        self.conv_last = nn.Conv2d(64, num_classes, kernel_size=1)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward pass with skip connections.\"\"\"\n",
    "        # Encoder\n",
    "        conv1 = self.dconv_down1(x)\n",
    "        x = self.maxpool(conv1)\n",
    "        \n",
    "        conv2 = self.dconv_down2(x)\n",
    "        x = self.maxpool(conv2)\n",
    "        \n",
    "        conv3 = self.dconv_down3(x)\n",
    "        x = self.maxpool(conv3)\n",
    "        \n",
    "        x = self.dconv_down4(x)\n",
    "        \n",
    "        # Decoder with skip connections\n",
    "        x = F.interpolate(x, size=conv3.shape[2:], mode=\"bilinear\", align_corners=False)\n",
    "        x = torch.cat([x, conv3], dim=1)\n",
    "        x = self.dconv_up3(x)\n",
    "        \n",
    "        x = F.interpolate(x, size=conv2.shape[2:], mode=\"bilinear\", align_corners=False)\n",
    "        x = torch.cat([x, conv2], dim=1)\n",
    "        x = self.dconv_up2(x)\n",
    "        \n",
    "        x = F.interpolate(x, size=conv1.shape[2:], mode=\"bilinear\", align_corners=False)\n",
    "        x = torch.cat([x, conv1], dim=1)\n",
    "        x = self.dconv_up1(x)\n",
    "        \n",
    "        return self.conv_last(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Loading\n",
    "\n",
    "Load the config and weights, stripping the `network.` prefix from state dict keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-05T13:37:23.815508Z",
     "iopub.status.busy": "2026-02-05T13:37:23.815392Z",
     "iopub.status.idle": "2026-02-05T13:37:23.818306Z",
     "shell.execute_reply": "2026-02-05T13:37:23.817845Z"
    }
   },
   "outputs": [],
   "source": [
    "# Paths\n",
    "MODEL_DIR = Path(\"../scratch/FloodMapper/resources/models/WF2_unet_rbgiswirs\")\n",
    "CONFIG_PATH = MODEL_DIR / \"config.json\"\n",
    "WEIGHTS_PATH = MODEL_DIR / \"model.pt\"\n",
    "\n",
    "# Load config\n",
    "with open(CONFIG_PATH) as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "hyperparams = config[\"model_params\"][\"hyperparameters\"]\n",
    "print(\"Model config:\")\n",
    "print(f\"  Channel configuration: {hyperparams['channel_configuration']}\")\n",
    "print(f\"  Number of classes: {hyperparams['num_classes']}\")\n",
    "print(f\"  Label names: {hyperparams['label_names']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-05T13:37:23.819516Z",
     "iopub.status.busy": "2026-02-05T13:37:23.819404Z",
     "iopub.status.idle": "2026-02-05T13:37:23.858407Z",
     "shell.execute_reply": "2026-02-05T13:37:23.857896Z"
    }
   },
   "outputs": [],
   "source": [
    "def strip_prefix(state_dict: dict, prefix: str = \"network.\") -> dict:\n",
    "    \"\"\"\n",
    "    Remove prefix from state dict keys.\n",
    "    \n",
    "    The ml4floods checkpoint saves weights as \"network.dconv_down1.0.weight\"\n",
    "    but our UNet expects \"dconv_down1.0.weight\".\n",
    "    \"\"\"\n",
    "    return {k.replace(prefix, \"\"): v for k, v in state_dict.items()}\n",
    "\n",
    "\n",
    "# Load and prepare model\n",
    "# Determine input channels from bgriswirs = 6 bands\n",
    "IN_CHANNELS = 6  # B03, B04, B08, B8A, B11, B12\n",
    "NUM_CLASSES = hyperparams[\"num_classes\"]  # 2 (water head, cloud head)\n",
    "\n",
    "model = UNet(in_channels=IN_CHANNELS, num_classes=NUM_CLASSES)\n",
    "\n",
    "# Load weights\n",
    "state_dict = torch.load(WEIGHTS_PATH, map_location=device, weights_only=True)\n",
    "state_dict = strip_prefix(state_dict, \"network.\")\n",
    "model.load_state_dict(state_dict)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(f\"Model loaded successfully with {sum(p.numel() for p in model.parameters()):,} parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Loading\n",
    "\n",
    "Load a tile from the Sentinel-2 GeoTIFF and apply normalization.\n",
    "\n",
    "**Band order in GeoTIFF:** B03 (Green), B04 (Red), B08 (NIR), B8A (NIR2), B11 (SWIR1), B12 (SWIR2), SCL\n",
    "\n",
    "**Model expects:** First 6 bands (excluding SCL), normalized per-band."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-05T13:37:23.860142Z",
     "iopub.status.busy": "2026-02-05T13:37:23.859956Z",
     "iopub.status.idle": "2026-02-05T13:37:23.863323Z",
     "shell.execute_reply": "2026-02-05T13:37:23.862850Z"
    }
   },
   "outputs": [],
   "source": [
    "# Normalization constants from ml4floods SENTINEL2_NORMALIZATION\n",
    "# Format: [mean, std] for each band in bgriswirs order\n",
    "NORMALIZATION = {\n",
    "    \"B03\": [3238.08, 2549.49],  # Green\n",
    "    \"B04\": [3418.90, 2811.78],  # Red\n",
    "    \"B08\": [3981.96, 2500.48],  # NIR\n",
    "    \"B8A\": [4226.75, 2589.29],  # NIR2\n",
    "    \"B11\": [2391.66, 1500.03],  # SWIR1\n",
    "    \"B12\": [1790.32, 1241.98],  # SWIR2\n",
    "}\n",
    "\n",
    "BAND_ORDER = [\"B03\", \"B04\", \"B08\", \"B8A\", \"B11\", \"B12\"]\n",
    "\n",
    "# Create normalization arrays\n",
    "means = np.array([NORMALIZATION[b][0] for b in BAND_ORDER], dtype=np.float32)\n",
    "stds = np.array([NORMALIZATION[b][1] for b in BAND_ORDER], dtype=np.float32)\n",
    "\n",
    "print(\"Normalization constants:\")\n",
    "for i, band in enumerate(BAND_ORDER):\n",
    "    print(f\"  {band}: mean={means[i]:.2f}, std={stds[i]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-05T13:37:23.864744Z",
     "iopub.status.busy": "2026-02-05T13:37:23.864638Z",
     "iopub.status.idle": "2026-02-05T13:37:23.960104Z",
     "shell.execute_reply": "2026-02-05T13:37:23.959685Z"
    }
   },
   "outputs": [],
   "source": "# Load GeoTIFF and get metadata\nGEOTIFF_PATH = Path(\"../DATA/37MGT/2025-12-17_S2L2A.tif\")\n\n# Open file and keep reference for interactive use\nsrc = rasterio.open(GEOTIFF_PATH)\n\nprint(f\"GeoTIFF info:\")\nprint(f\"  Shape: {src.count} bands x {src.height} x {src.width}\")\nprint(f\"  Band names: {src.descriptions}\")\nprint(f\"  CRS: {src.crs}\")\n\n# Store image dimensions\nimg_height = src.height\nimg_width = src.width\ntile_size = 1024\n\nprint(f\"\\nImage dimensions: {img_height} x {img_width}\")\nprint(f\"Tile size: {tile_size} x {tile_size}\")"
  },
  {
   "cell_type": "markdown",
   "source": "## 5. Interactive Tile Selection\n\nUse the sliders below to select a tile location. The red rectangle shows the selected 1024x1024 region.\nWhen you've found an interesting area, run the next cell to execute inference.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Create downsampled thumbnail for overview visualization\nthumbnail_scale = 10\nthumbnail_height = img_height // thumbnail_scale\nthumbnail_width = img_width // thumbnail_scale\n\n# Read RGB bands (B04=Red, B03=Green) at reduced resolution\nthumbnail_rgb = src.read(\n    [2, 1, 1],  # B04, B03, B03 for pseudo-RGB\n    out_shape=(3, thumbnail_height, thumbnail_width)\n).astype(np.float32)\n\n# Scale thumbnail for display\np2, p98 = np.percentile(thumbnail_rgb, [2, 98])\nthumbnail_display = np.clip((thumbnail_rgb - p2) / (p98 - p2), 0, 1)\nthumbnail_display = np.transpose(thumbnail_display, (1, 2, 0))  # CHW -> HWC\n\n# Calculate slider ranges for interactive selection\nmax_row = img_height - tile_size\nmax_col = img_width - tile_size\ncenter_row = max_row // 2\ncenter_col = max_col // 2\n\nprint(f\"Thumbnail shape: {thumbnail_display.shape}\")\nprint(f\"Tile selection range: row [0, {max_row}], col [0, {max_col}]\")\nprint(f\"Center position: row={center_row}, col={center_col}\")\n\n\ndef extract_tile(row_start: int, col_start: int, tile_size: int = 1024):\n    \"\"\"\n    Extract a tile from the GeoTIFF at specified location.\n    \n    Parameters\n    ----------\n    row_start : int\n        Starting row (y coordinate) for the tile.\n    col_start : int\n        Starting column (x coordinate) for the tile.\n    tile_size : int\n        Size of the square tile to extract.\n    \n    Returns\n    -------\n    tuple\n        tile: np.ndarray of shape (6, tile_size, tile_size) with raw values\n        scl: np.ndarray of shape (tile_size, tile_size) with SCL values\n    \"\"\"\n    window = rasterio.windows.Window(col_start, row_start, tile_size, tile_size)\n    tile = src.read([1, 2, 3, 4, 5, 6], window=window).astype(np.float32)\n    scl = src.read(7, window=window)\n    return tile, scl",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-05T13:37:23.961410Z",
     "iopub.status.busy": "2026-02-05T13:37:23.961313Z",
     "iopub.status.idle": "2026-02-05T13:37:23.971390Z",
     "shell.execute_reply": "2026-02-05T13:37:23.970939Z"
    }
   },
   "outputs": [],
   "source": "# === Helper Functions for Processing Pipeline ===\n\ndef normalize_tile(tile: np.ndarray, means: np.ndarray, stds: np.ndarray) -> np.ndarray:\n    \"\"\"Apply per-band normalization: (value - mean) / std\"\"\"\n    means_reshaped = means[:, np.newaxis, np.newaxis]\n    stds_reshaped = stds[:, np.newaxis, np.newaxis]\n    return (tile - means_reshaped) / stds_reshaped\n\n\ndef pad_to_multiple(x: torch.Tensor, multiple: int = 16) -> tuple[torch.Tensor, tuple[int, int]]:\n    \"\"\"Pad tensor height and width to be divisible by multiple.\"\"\"\n    h, w = x.shape[-2:]\n    pad_h = (multiple - h % multiple) % multiple\n    pad_w = (multiple - w % multiple) % multiple\n    if pad_h > 0 or pad_w > 0:\n        x = F.pad(x, (0, pad_w, 0, pad_h), mode=\"reflect\")\n    return x, (h, w)\n\n\n@torch.no_grad()\ndef run_inference(model: nn.Module, tile: np.ndarray, device: torch.device) -> tuple[np.ndarray, np.ndarray]:\n    \"\"\"Run inference on a normalized tile, returns (water_prob, cloud_prob).\"\"\"\n    x = torch.from_numpy(tile).unsqueeze(0).to(device)\n    x_padded, (orig_h, orig_w) = pad_to_multiple(x, multiple=16)\n    logits = model(x_padded)\n    probs = torch.sigmoid(logits)\n    probs = probs[0, :, :orig_h, :orig_w].cpu().numpy()\n    return probs[0], probs[1]  # water_prob, cloud_prob\n\n\ndef classify_prediction(water_prob: np.ndarray, cloud_prob: np.ndarray,\n                        invalid_mask: np.ndarray | None = None,\n                        th_water: float = 0.5, th_cloud: float = 0.5) -> np.ndarray:\n    \"\"\"Classify pixels: 0=invalid, 1=land, 2=water, 3=cloud.\"\"\"\n    pred = np.ones_like(water_prob, dtype=np.uint8)\n    pred[water_prob > th_water] = 2\n    pred[cloud_prob > th_cloud] = 3\n    if invalid_mask is not None:\n        pred[invalid_mask] = 0\n    return pred\n\n\ndef create_rgb_composite(tile: np.ndarray, bands: tuple[int, int, int] = (1, 0, 0)) -> np.ndarray:\n    \"\"\"Create an RGB composite for visualization.\"\"\"\n    rgb = np.stack([tile[b] for b in bands], axis=-1)\n    p2, p98 = np.percentile(rgb, [2, 98])\n    return np.clip((rgb - p2) / (p98 - p2), 0, 1)\n\n\n# Classification colormap and labels\ncolors = [[0, 0, 0, 1], [0.76, 0.70, 0.50, 1], [0, 0.3, 0.8, 1], [0.9, 0.9, 0.9, 1]]\ncmap = ListedColormap(colors)\nclass_names = {0: \"Invalid\", 1: \"Land\", 2: \"Water\", 3: \"Cloud\"}\n\nprint(\"Helper functions defined.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-05T13:37:28.018277Z",
     "iopub.status.busy": "2026-02-05T13:37:28.018183Z",
     "iopub.status.idle": "2026-02-05T13:37:28.360579Z",
     "shell.execute_reply": "2026-02-05T13:37:28.360084Z"
    }
   },
   "outputs": [],
   "source": "from ipywidgets import interact, IntSlider\n\n# Create sliders (these persist between cells)\nrow_slider = IntSlider(min=0, max=max_row, step=256, value=center_row, \n                       description='Row:', continuous_update=False)\ncol_slider = IntSlider(min=0, max=max_col, step=256, value=center_col, \n                       description='Col:', continuous_update=False)\n\n@interact(row_start=row_slider, col_start=col_slider)\ndef show_tile_selection(row_start, col_start):\n    \"\"\"Show thumbnail with selected tile location (lightweight - no inference).\"\"\"\n    fig, ax = plt.subplots(figsize=(6, 6))\n    ax.imshow(thumbnail_display)\n    \n    # Scale rectangle to thumbnail coordinates\n    scale_row = thumbnail_display.shape[0] / img_height\n    scale_col = thumbnail_display.shape[1] / img_width\n    \n    rect = plt.Rectangle(\n        (col_start * scale_col, row_start * scale_row),\n        tile_size * scale_col, tile_size * scale_row,\n        fill=False, edgecolor='red', linewidth=2\n    )\n    ax.add_patch(rect)\n    ax.set_title(f\"Selected tile: row={row_start}, col={col_start}\")\n    ax.axis('off')\n    plt.tight_layout()\n    plt.show()"
  },
  {
   "cell_type": "markdown",
   "source": "## 6. Run Inference\n\nExecute this cell to run inference on the currently selected tile position.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Get current slider values\nrow_start = row_slider.value\ncol_start = col_slider.value\n\nprint(f\"Running inference on tile at row={row_start}, col={col_start}...\")\n\n# Extract tile\ntile, scl = extract_tile(row_start, col_start, tile_size)\nprint(f\"  Tile shape: {tile.shape}, value range: [{tile.min():.0f}, {tile.max():.0f}]\")\n\n# Normalize and run inference\ntile_normalized = normalize_tile(tile, means, stds)\nwater_prob, cloud_prob = run_inference(model, tile_normalized, device)\nprint(f\"  Water prob: [{water_prob.min():.3f}, {water_prob.max():.3f}]\")\nprint(f\"  Cloud prob: [{cloud_prob.min():.3f}, {cloud_prob.max():.3f}]\")\n\n# Classify\ninvalid_mask = np.all(tile == 0, axis=0)\nprediction = classify_prediction(water_prob, cloud_prob, invalid_mask)\n\n# Print class distribution\nunique, counts = np.unique(prediction, return_counts=True)\nprint(\"\\nClassification results:\")\nfor cls, count in zip(unique, counts):\n    pct = 100 * count / prediction.size\n    print(f\"  {class_names[cls]}: {count:,} pixels ({pct:.1f}%)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 7. Visualization\n\nDisplay the RGB composite, classification map, and false color composites.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Main visualization: RGB, Classification, Water Probability\nrgb = create_rgb_composite(tile, bands=(1, 0, 0))\n\nfig1, axes = plt.subplots(1, 3, figsize=(15, 5))\n\naxes[0].imshow(rgb)\naxes[0].set_title(\"RGB Composite (B04, B03, B03)\")\naxes[0].axis(\"off\")\n\nim = axes[1].imshow(prediction, cmap=cmap, vmin=0, vmax=3)\naxes[1].set_title(\"Classification\")\naxes[1].axis(\"off\")\ncbar = plt.colorbar(im, ax=axes[1], ticks=[0, 1, 2, 3], shrink=0.8)\ncbar.ax.set_yticklabels([\"Invalid\", \"Land\", \"Water\", \"Cloud\"])\n\nim2 = axes[2].imshow(water_prob, cmap=\"Blues\", vmin=0, vmax=1)\naxes[2].set_title(\"Water Probability\")\naxes[2].axis(\"off\")\nplt.colorbar(im2, ax=axes[2], shrink=0.8)\n\nplt.suptitle(f\"Tile at row={row_start}, col={col_start}\", fontsize=12)\nplt.tight_layout()\nplt.show()\n\n# False color composites\nfig2, axes = plt.subplots(1, 2, figsize=(12, 5))\n\nfalse_color = create_rgb_composite(tile, bands=(2, 1, 0))\naxes[0].imshow(false_color)\naxes[0].set_title(\"False Color (NIR-Red-Green)\\nWater appears dark\")\naxes[0].axis(\"off\")\n\nswir_color = create_rgb_composite(tile, bands=(4, 2, 1))\naxes[1].imshow(swir_color)\naxes[1].set_title(\"SWIR Composite (SWIR1-NIR-Red)\\nWater appears very dark\")\naxes[1].axis(\"off\")\n\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Summary\n\nThis notebook demonstrated:\n\n1. **Self-contained UNet implementation** - No ml4floods dependency required\n2. **Model loading** - Strip `network.` prefix from state dict keys  \n3. **Data loading** - Open GeoTIFF with rasterio, create thumbnail overview\n4. **Interactive tile selection** - Use sliders to explore the image (lightweight)\n5. **Inference pipeline** - Run on-demand when you've selected a tile\n6. **Visualization** - RGB composite, classification map, and false color views\n\n**Workflow:**\n1. Use the sliders in Section 5 to explore the image and select a tile\n2. When ready, execute Section 6 to run inference on the selected tile\n3. Execute Section 7 to visualize the results\n4. Return to Section 5 to select a new tile and repeat\n\nThe model produces two probability outputs (water, cloud) which are thresholded at 0.5 to produce discrete classes."
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maji",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}