{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference from scratch\n",
    "\n",
    "This notebook demonstrates water/cloud classification using the WorldFloods UNet model\n",
    "on a Sentinel-2 GeoTIFF tile.\n",
    "\n",
    "**Key features:**\n",
    "- Self-contained UNet implementation (no ml4floods dependency)\n",
    "- Loads pre-trained WF2_unet_rbgiswirs weights\n",
    "- **Interactive tile selection** - explore different regions using sliders or preset buttons\n",
    "- Visualizes RGB input and water/cloud prediction\n",
    "\n",
    "\n",
    "BANDS_S2 = [\"B1\", \"B2\", \"B3\", \"B4\", \"B5\", \"B6\", \"B7\", \"B8\", \"B8A\", \"B9\", \"B10\", \"B11\", \"B12\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-05T13:37:22.584175Z",
     "iopub.status.busy": "2026-02-05T13:37:22.583997Z",
     "iopub.status.idle": "2026-02-05T13:37:23.788265Z",
     "shell.execute_reply": "2026-02-05T13:37:23.787776Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# Check for GPU (CUDA > MPS > CPU)\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define the UNet Architecture\n",
    "\n",
    "The WorldFloods *WF2_unet_rbgiswirs* model is a tandard 4-level encoder/decoder with skip connections.\n",
    "\n",
    "It expects the channel configuration 'bgriswirs' from ML4FLoods, which is [1, 2, 3, 7, 11, 12] in a 0-based = \n",
    "MODEL_BANDS = ['B02', 'B03', 'B04', 'B08', 'B11', 'B12']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-05T13:37:23.808673Z",
     "iopub.status.busy": "2026-02-05T13:37:23.808459Z",
     "iopub.status.idle": "2026-02-05T13:37:23.814101Z",
     "shell.execute_reply": "2026-02-05T13:37:23.813478Z"
    }
   },
   "outputs": [],
   "source": [
    "def _double_conv(in_ch: int, out_ch: int) -> nn.Sequential:\n",
    "    \"\"\"Two consecutive Conv2d-ReLU blocks.\"\"\"\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1),\n",
    "        nn.ReLU(inplace=True),\n",
    "    )\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    \"\"\"\n",
    "    4-level UNet for semantic segmentation.\n",
    "    \n",
    "    Architecture:\n",
    "        Encoder: 4 double-conv blocks with max pooling\n",
    "        Decoder: 3 upsampling + skip connection + double-conv blocks\n",
    "        Output: 1x1 conv to num_classes\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    in_channels : int\n",
    "        Number of input channels (e.g., 6 for bgriswirs bands).\n",
    "    num_classes : int\n",
    "        Number of output classes (2 for water/cloud binary heads).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels: int, num_classes: int):\n",
    "        super().__init__()\n",
    "        # Encoder\n",
    "        self.dconv_down1 = _double_conv(in_channels, 64)\n",
    "        self.dconv_down2 = _double_conv(64, 128)\n",
    "        self.dconv_down3 = _double_conv(128, 256)\n",
    "        self.dconv_down4 = _double_conv(256, 512)\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "        \n",
    "        # Decoder\n",
    "        self.dconv_up3 = _double_conv(256 + 512, 256)\n",
    "        self.dconv_up2 = _double_conv(128 + 256, 128)\n",
    "        self.dconv_up1 = _double_conv(64 + 128, 64)\n",
    "        \n",
    "        # Output\n",
    "        self.conv_last = nn.Conv2d(64, num_classes, kernel_size=1)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward pass with skip connections.\"\"\"\n",
    "        # Encoder\n",
    "        conv1 = self.dconv_down1(x)\n",
    "        x = self.maxpool(conv1)\n",
    "        \n",
    "        conv2 = self.dconv_down2(x)\n",
    "        x = self.maxpool(conv2)\n",
    "        \n",
    "        conv3 = self.dconv_down3(x)\n",
    "        x = self.maxpool(conv3)\n",
    "        \n",
    "        x = self.dconv_down4(x)\n",
    "        \n",
    "        # Decoder with skip connections\n",
    "        x = F.interpolate(x, size=conv3.shape[2:], mode=\"bilinear\", align_corners=False)\n",
    "        x = torch.cat([x, conv3], dim=1)\n",
    "        x = self.dconv_up3(x)\n",
    "        \n",
    "        x = F.interpolate(x, size=conv2.shape[2:], mode=\"bilinear\", align_corners=False)\n",
    "        x = torch.cat([x, conv2], dim=1)\n",
    "        x = self.dconv_up2(x)\n",
    "        \n",
    "        x = F.interpolate(x, size=conv1.shape[2:], mode=\"bilinear\", align_corners=False)\n",
    "        x = torch.cat([x, conv1], dim=1)\n",
    "        x = self.dconv_up1(x)\n",
    "        \n",
    "        return self.conv_last(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Loading\n",
    "\n",
    "Load the config and weights, stripping the `network.` prefix from state dict keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-05T13:37:23.815508Z",
     "iopub.status.busy": "2026-02-05T13:37:23.815392Z",
     "iopub.status.idle": "2026-02-05T13:37:23.818306Z",
     "shell.execute_reply": "2026-02-05T13:37:23.817845Z"
    }
   },
   "outputs": [],
   "source": [
    "# Paths\n",
    "MODEL_DIR = Path(\"../models/WF2_unet_rbgiswirs\")  # Default model\n",
    "CONFIG_PATH = MODEL_DIR / \"config.json\"           # Training config file\n",
    "WEIGHTS_PATH = MODEL_DIR / \"model.pt\"             # Model weights file\n",
    "\n",
    "# Load config\n",
    "with open(CONFIG_PATH) as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# Need to read the hyperparameters: num_classes, channel_configuration\n",
    "# TODO: Check if we should read label names also\n",
    "hyperparams = config[\"model_params\"][\"hyperparameters\"]\n",
    "print(\"Model config:\")\n",
    "print(f\"  Channel configuration: {hyperparams['channel_configuration']}\")\n",
    "print(f\"  Number of classes: {hyperparams['num_classes']}\")\n",
    "print(f\"  Label names: {hyperparams['label_names']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-05T13:37:23.819516Z",
     "iopub.status.busy": "2026-02-05T13:37:23.819404Z",
     "iopub.status.idle": "2026-02-05T13:37:23.858407Z",
     "shell.execute_reply": "2026-02-05T13:37:23.857896Z"
    }
   },
   "outputs": [],
   "source": [
    "def strip_prefix(state_dict: dict, prefix: str = \"network.\") -> dict:\n",
    "    \"\"\"\n",
    "    Remove prefix from state dict keys.\n",
    "    \n",
    "    The ml4floods checkpoint saves weights as \"network.dconv_down1.0.weight\"\n",
    "    but our UNet expects \"dconv_down1.0.weight\".\n",
    "    \"\"\"\n",
    "    return {k.replace(prefix, \"\"): v for k, v in state_dict.items()}\n",
    "\n",
    "\n",
    "# Load and prepare model\n",
    "# Determine input channels from bgriswirs = 6 bands\n",
    "IN_CHANNELS = 6  # B03, B04, B08, B8A, B11, B12\n",
    "NUM_CLASSES = hyperparams[\"num_classes\"]  # 2 (water head, cloud head)\n",
    "\n",
    "model = UNet(in_channels=IN_CHANNELS, num_classes=NUM_CLASSES)\n",
    "\n",
    "# Load weights\n",
    "state_dict = torch.load(WEIGHTS_PATH, map_location=device, weights_only=True)\n",
    "state_dict = strip_prefix(state_dict, \"network.\")\n",
    "model.load_state_dict(state_dict)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(f\"Model loaded successfully with {sum(p.numel() for p in model.parameters()):,} parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Loading\n",
    "\n",
    "Load a tile from the Sentinel-2 GeoTIFF and apply normalization.\n",
    "\n",
    "**Band order in GeoTIFF:** B03 (Green), B04 (Red), B08 (NIR), B8A (NIR2), B11 (SWIR1), B12 (SWIR2), SCL\n",
    "\n",
    "**Model expects:** First 6 bands (excluding SCL), normalized per-band."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BANDS_S2 = [\"B1\", \"B2\", \"B3\", \"B4\", \"B5\", \"B6\", \"B7\", \"B8\", \"B8A\", \"B9\", \"B10\", \"B11\", \"B12\"]\n",
    "\n",
    "CHANNELS_CONFIGURATIONS = {\n",
    "    \"all\": list(range(0,len(BANDS_S2))),\n",
    "    \"rgb\": [3, 2, 1],\n",
    "    \"swirnirred\": [11, 7, 3],\n",
    "    \"bgr\": [1, 2, 3],\n",
    "    \"bgri\": [1, 2, 3, 7],\n",
    "    \"riswir\" : [3, 7, 11],\n",
    "    \"bgriswir\" : [1, 2, 3, 7, 11],\n",
    "    \"bgriswirs\" : [1, 2, 3, 7, 11, 12],\n",
    "    \"l89s2\": [0, 1, 2, 3, 7, 10, 11, 12], # Same bands as Landsat-7 and Landsat-8\n",
    "    \"sub_20\": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12],\n",
    "    \"hyperscout2\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "}\n",
    "\n",
    "SENTINEL2_NORMALIZATION = np.array(\n",
    "    [\n",
    "        [3787.0604973, 2634.44474043],  # 01\n",
    "        [3758.07467509, 2794.09579088], # 02\n",
    "        [3238.08247208, 2549.4940614],  # 03\n",
    "        [3418.90147615, 2811.78109878], # 04\n",
    "        [3450.23315812, 2776.93269704], # 05\n",
    "        [4030.94700446, 2632.13814197], # 06\n",
    "        [4164.17468251, 2657.43035126], # 07\n",
    "        [3981.96268494, 2500.47885249], # 08\n",
    "        [4226.74862547, 2589.29159887], # 09\n",
    "        [1868.29658114, 1820.90184704], # 10\n",
    "        [399.3878948, 761.3640411],     # 11\n",
    "        [2391.66101119, 1500.02533014], # 12\n",
    "        [1790.32497137, 1241.9817628],\n",
    "    ],\n",
    "    dtype=np.float32,\n",
    ")\n",
    "\n",
    "\n",
    "[BANDS_S2[i] for i in CHANNELS_CONFIGURATIONS.get('bgriswirs')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-05T13:37:23.860142Z",
     "iopub.status.busy": "2026-02-05T13:37:23.859956Z",
     "iopub.status.idle": "2026-02-05T13:37:23.863323Z",
     "shell.execute_reply": "2026-02-05T13:37:23.862850Z"
    }
   },
   "outputs": [],
   "source": [
    "# Normalization constants from ml4floods SENTINEL2_NORMALIZATION\n",
    "# Format: [mean, std] for each band in bgriswirs order\n",
    "NORMALIZATION = {\n",
    "    \"B02\": [3758.08, 2794.10],  # Blue\n",
    "    \"B03\": [3238.08, 2549.49],  # Green\n",
    "    \"B04\": [3418.90, 2811.78],  # Red\n",
    "    \"B08\": [3981.96, 2500.48],  # NIR\n",
    "    \"B8A\": [4226.75, 2589.29],  # NIR2\n",
    "    \"B11\": [2391.66, 1500.03],  # SWIR1\n",
    "    \"B12\": [1790.32, 1241.98],  # SWIR2\n",
    "}\n",
    "\n",
    "BAND_ORDER = ['B02', 'B03', 'B04', 'B08', 'B11', 'B12']\n",
    "\n",
    "# Create normalization arrays\n",
    "means = np.array([NORMALIZATION[b][0] for b in BAND_ORDER], dtype=np.float32)\n",
    "stds = np.array([NORMALIZATION[b][1] for b in BAND_ORDER], dtype=np.float32)\n",
    "\n",
    "print(\"Normalization constants:\")\n",
    "for i, band in enumerate(BAND_ORDER):\n",
    "    print(f\"  {band}: mean={means[i]:.2f}, std={stds[i]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-05T13:37:23.864744Z",
     "iopub.status.busy": "2026-02-05T13:37:23.864638Z",
     "iopub.status.idle": "2026-02-05T13:37:23.960104Z",
     "shell.execute_reply": "2026-02-05T13:37:23.959685Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load GeoTIFF and get metadata\n",
    "GEOTIFF_PATH = Path(\"../DATA/37MGT/2025-12-17_S2L2A.tif\")\n",
    "\n",
    "# Open file and keep reference for interactive use\n",
    "src = rasterio.open(GEOTIFF_PATH)\n",
    "\n",
    "print(f\"GeoTIFF info:\")\n",
    "print(f\"  Shape: {src.count} bands x {src.height} x {src.width}\")\n",
    "print(f\"  Band names: {src.descriptions}\")\n",
    "print(f\"  CRS: {src.crs}\")\n",
    "\n",
    "# Store image dimensions\n",
    "img_height = src.height\n",
    "img_width = src.width\n",
    "tile_size = 1024\n",
    "\n",
    "print(f\"\\nImage dimensions: {img_height} x {img_width}\")\n",
    "print(f\"Tile size: {tile_size} x {tile_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Interactive Tile Selection\n",
    "\n",
    "Use the sliders below to select a tile location. The red rectangle shows the selected 1024x1024 region.\n",
    "When you've found an interesting area, run the next cell to execute inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create downsampled thumbnail for overview visualization\n",
    "thumbnail_scale = 10\n",
    "thumbnail_height = img_height // thumbnail_scale\n",
    "thumbnail_width = img_width // thumbnail_scale\n",
    "\n",
    "# Read bands for false color composite at reduced resolution\n",
    "# B11 (SWIR), B08 (NIR), B03 (Green) - water appears dark, vegetation bright green\n",
    "thumbnail_rgb = src.read(\n",
    "    [5, 4, 2],  # B11 (SWIR), B08 (NIR), B03 (Green)\n",
    "    out_shape=(3, thumbnail_height, thumbnail_width)\n",
    ").astype(np.float32)\n",
    "\n",
    "# Per-channel percentile stretch for better contrast\n",
    "thumbnail_display = np.zeros((thumbnail_height, thumbnail_width, 3), dtype=np.float32)\n",
    "for i in range(3):\n",
    "    p2, p98 = np.percentile(thumbnail_rgb[i], [2, 98])\n",
    "    thumbnail_display[:, :, i] = np.clip((thumbnail_rgb[i] - p2) / (p98 - p2 + 1e-8), 0, 1)\n",
    "\n",
    "# Calculate slider ranges for interactive selection\n",
    "max_row = img_height - tile_size\n",
    "max_col = img_width - tile_size\n",
    "center_row = max_row // 2\n",
    "center_col = max_col // 2\n",
    "\n",
    "print(f\"Thumbnail shape: {thumbnail_display.shape}\")\n",
    "print(f\"Tile selection range: row [0, {max_row}], col [0, {max_col}]\")\n",
    "print(f\"Center position: row={center_row}, col={center_col}\")\n",
    "\n",
    "\n",
    "def extract_tile(row_start: int, col_start: int, tile_size: int = 1024):\n",
    "    \"\"\"\n",
    "    Extract a tile from the GeoTIFF at specified location.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    row_start : int\n",
    "        Starting row (y coordinate) for the tile.\n",
    "    col_start : int\n",
    "        Starting column (x coordinate) for the tile.\n",
    "    tile_size : int\n",
    "        Size of the square tile to extract.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        tile: np.ndarray of shape (6, tile_size, tile_size) with raw values\n",
    "        scl: np.ndarray of shape (tile_size, tile_size) with SCL values\n",
    "    \"\"\"\n",
    "    window = rasterio.windows.Window(col_start, row_start, tile_size, tile_size)\n",
    "    tile = src.read([1, 2, 3, 4, 5, 6], window=window).astype(np.float32)\n",
    "    scl = src.read(7, window=window)\n",
    "    return tile, scl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-05T13:37:23.961410Z",
     "iopub.status.busy": "2026-02-05T13:37:23.961313Z",
     "iopub.status.idle": "2026-02-05T13:37:23.971390Z",
     "shell.execute_reply": "2026-02-05T13:37:23.970939Z"
    }
   },
   "outputs": [],
   "source": [
    "# === Helper Functions for Processing Pipeline ===\n",
    "\n",
    "def normalize_tile(tile: np.ndarray, means: np.ndarray, stds: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Apply per-band normalization: (value - mean) / std\"\"\"\n",
    "    means_reshaped = means[:, np.newaxis, np.newaxis]\n",
    "    stds_reshaped = stds[:, np.newaxis, np.newaxis]\n",
    "    return (tile - means_reshaped) / stds_reshaped\n",
    "\n",
    "\n",
    "def pad_to_multiple(x: torch.Tensor, multiple: int = 16) -> tuple[torch.Tensor, tuple[int, int]]:\n",
    "    \"\"\"Pad tensor height and width to be divisible by multiple.\"\"\"\n",
    "    h, w = x.shape[-2:]\n",
    "    pad_h = (multiple - h % multiple) % multiple\n",
    "    pad_w = (multiple - w % multiple) % multiple\n",
    "    if pad_h > 0 or pad_w > 0:\n",
    "        x = F.pad(x, (0, pad_w, 0, pad_h), mode=\"reflect\")\n",
    "    return x, (h, w)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def run_inference(model: nn.Module, tile: np.ndarray, device: torch.device) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Run inference on a normalized tile, returns (water_prob, cloud_prob).\"\"\"\n",
    "    x = torch.from_numpy(tile).unsqueeze(0).to(device)\n",
    "    x_padded, (orig_h, orig_w) = pad_to_multiple(x, multiple=16)\n",
    "    logits = model(x_padded)\n",
    "    probs = torch.sigmoid(logits)\n",
    "    probs = probs[0, :, :orig_h, :orig_w].cpu().numpy()\n",
    "    return probs[0], probs[1]  # water_prob, cloud_prob\n",
    "\n",
    "\n",
    "def classify_prediction(water_prob: np.ndarray, cloud_prob: np.ndarray,\n",
    "                        invalid_mask: np.ndarray | None = None,\n",
    "                        th_water: float = 0.5, th_cloud: float = 0.5) -> np.ndarray:\n",
    "    \"\"\"Classify pixels: 0=invalid, 1=land, 2=water, 3=cloud.\"\"\"\n",
    "    pred = np.ones_like(water_prob, dtype=np.uint8)\n",
    "    pred[water_prob > th_water] = 2\n",
    "    pred[cloud_prob > th_cloud] = 3\n",
    "    if invalid_mask is not None:\n",
    "        pred[invalid_mask] = 0\n",
    "    return pred\n",
    "\n",
    "\n",
    "def create_rgb_composite(tile: np.ndarray, bands: tuple[int, int, int] = (4, 3, 1)) -> np.ndarray:\n",
    "    \"\"\"Create a false color composite for visualization.\n",
    "\n",
    "    Default is SWIR-NIR-Green which highlights water (dark) vs vegetation (bright green).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    tile : np.ndarray\n",
    "        Input tile with shape (C, H, W) where channels are [B02, B03, B04, B08, B11, B12].\n",
    "    bands : tuple[int, int, int]\n",
    "        Indices for R, G, B channels. Default (4, 3, 1) = B11, B08, B03.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        RGB composite with shape (H, W, 3), values in [0, 1].\n",
    "    \"\"\"\n",
    "    rgb = np.stack([tile[b] for b in bands], axis=-1)\n",
    "    # Per-channel percentile stretch for better contrast\n",
    "    result = np.zeros_like(rgb)\n",
    "    for i in range(3):\n",
    "        p2, p98 = np.percentile(rgb[:, :, i], [2, 98])\n",
    "        result[:, :, i] = np.clip((rgb[:, :, i] - p2) / (p98 - p2 + 1e-8), 0, 1)\n",
    "    return result\n",
    "\n",
    "\n",
    "# Classification colormap and labels\n",
    "colors = [[0, 0, 0, 1], [0.76, 0.70, 0.50, 1], [0, 0.3, 0.8, 1], [0.9, 0.9, 0.9, 1]]\n",
    "cmap = ListedColormap(colors)\n",
    "class_names = {0: \"Invalid\", 1: \"Land\", 2: \"Water\", 3: \"Cloud\"}\n",
    "\n",
    "print(\"Helper functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-05T13:37:28.018277Z",
     "iopub.status.busy": "2026-02-05T13:37:28.018183Z",
     "iopub.status.idle": "2026-02-05T13:37:28.360579Z",
     "shell.execute_reply": "2026-02-05T13:37:28.360084Z"
    }
   },
   "outputs": [],
   "source": [
    "from ipywidgets import IntSlider, VBox, Output\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Create sliders (these persist between cells)\n",
    "row_slider = IntSlider(min=0, max=max_row, step=256, value=center_row,\n",
    "                       description='Row:', continuous_update=False)\n",
    "col_slider = IntSlider(min=0, max=max_col, step=256, value=center_col,\n",
    "                       description='Col:', continuous_update=False)\n",
    "\n",
    "# Create explicit output widget\n",
    "output_widget = Output()\n",
    "\n",
    "def show_tile_selection(change=None):\n",
    "    \"\"\"Show thumbnail with selected tile location (lightweight - no inference).\"\"\"\n",
    "    row_start = row_slider.value\n",
    "    col_start = col_slider.value\n",
    "\n",
    "    with output_widget:\n",
    "        clear_output(wait=True)\n",
    "        fig, ax = plt.subplots(figsize=(6, 6))\n",
    "        ax.imshow(thumbnail_display)\n",
    "\n",
    "        # Scale rectangle to thumbnail coordinates\n",
    "        scale_row = thumbnail_display.shape[0] / img_height\n",
    "        scale_col = thumbnail_display.shape[1] / img_width\n",
    "\n",
    "        rect = plt.Rectangle(\n",
    "            (col_start * scale_col, row_start * scale_row),\n",
    "            tile_size * scale_col, tile_size * scale_row,\n",
    "            fill=False, edgecolor='red', linewidth=2\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "        ax.set_title(f\"Selected tile: row={row_start}, col={col_start}\")\n",
    "        ax.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        plt.close(fig)  # Remove from matplotlib's figure registry\n",
    "\n",
    "# Connect slider changes to update function\n",
    "row_slider.observe(show_tile_selection, names='value')\n",
    "col_slider.observe(show_tile_selection, names='value')\n",
    "\n",
    "# Display widgets\n",
    "display(VBox([row_slider, col_slider, output_widget]))\n",
    "\n",
    "# Initial render\n",
    "show_tile_selection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Run Inference\n",
    "\n",
    "Execute this cell to run inference on the currently selected tile position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current slider values\n",
    "row_start = row_slider.value\n",
    "col_start = col_slider.value\n",
    "\n",
    "print(f\"Running inference on tile at row={row_start}, col={col_start}...\")\n",
    "\n",
    "# Extract tile\n",
    "tile, scl = extract_tile(row_start, col_start, tile_size)\n",
    "print(f\"  Tile shape: {tile.shape}, value range: [{tile.min():.0f}, {tile.max():.0f}]\")\n",
    "\n",
    "# Normalize and run inference\n",
    "tile_normalized = normalize_tile(tile, means, stds)\n",
    "#water_prob, cloud_prob = run_inference(model, tile_normalized, device)\n",
    "cloud_prob, water_prob = run_inference(model, tile_normalized, device)\n",
    "print(f\"  Water prob: [{water_prob.min():.3f}, {water_prob.max():.3f}]\")\n",
    "print(f\"  Cloud prob: [{cloud_prob.min():.3f}, {cloud_prob.max():.3f}]\")\n",
    "\n",
    "# Classify\n",
    "invalid_mask = np.all(tile == 0, axis=0)\n",
    "prediction = classify_prediction(water_prob, cloud_prob, invalid_mask, \n",
    "                                 th_water=0.5, th_cloud=0.98)\n",
    "\n",
    "# Print class distribution\n",
    "unique, counts = np.unique(prediction, return_counts=True)\n",
    "print(\"\\nClassification results:\")\n",
    "for cls, count in zip(unique, counts):\n",
    "    pct = 100 * count / prediction.size\n",
    "    print(f\"  {class_names[cls]}: {count:,} pixels ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualization\n",
    "\n",
    "Display the RGB composite, classification map, and false color composites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main visualization: Cloud Prob, Water Prob, False Color, Classification\n",
    "rgb = create_rgb_composite(tile, bands=(4, 3, 1))\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
    "\n",
    "# Cloud probability\n",
    "im_cloud = axes[0, 0].imshow(cloud_prob, cmap=\"Greys\", vmin=0, vmax=1)\n",
    "axes[0, 0].set_title(f\"Cloud Probability\\n[{cloud_prob.min():.2f}, {cloud_prob.max():.2f}]\")\n",
    "axes[0, 0].axis(\"off\")\n",
    "plt.colorbar(im_cloud, ax=axes[0, 0], shrink=0.8)\n",
    "\n",
    "# Water probability\n",
    "im_water = axes[0, 1].imshow(water_prob, cmap=\"Blues\", vmin=0, vmax=1)\n",
    "axes[0, 1].set_title(f\"Water Probability\\n[{water_prob.min():.2f}, {water_prob.max():.2f}]\")\n",
    "axes[0, 1].axis(\"off\")\n",
    "plt.colorbar(im_water, ax=axes[0, 1], shrink=0.8)\n",
    "\n",
    "# False color composite\n",
    "axes[1, 0].imshow(rgb)\n",
    "axes[1, 0].set_title(\"False Color (SWIR-NIR-Green)\")\n",
    "axes[1, 0].axis(\"off\")\n",
    "\n",
    "# Final classification\n",
    "im_class = axes[1, 1].imshow(prediction, cmap=cmap, vmin=0, vmax=3)\n",
    "axes[1, 1].set_title(\"Classification Mask\")\n",
    "axes[1, 1].axis(\"off\")\n",
    "cbar = plt.colorbar(im_class, ax=axes[1, 1], ticks=[0, 1, 2, 3], shrink=0.8)\n",
    "cbar.ax.set_yticklabels([\"Invalid\", \"Land\", \"Water\", \"Cloud\"])\n",
    "\n",
    "plt.suptitle(f\"Tile at row={row_start}, col={col_start}\", fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **Self-contained UNet implementation** - No ml4floods dependency required\n",
    "2. **Model loading** - Strip `network.` prefix from state dict keys  \n",
    "3. **Data loading** - Open GeoTIFF with rasterio, create thumbnail overview\n",
    "4. **Interactive tile selection** - Use sliders to explore the image (lightweight)\n",
    "5. **Inference pipeline** - Run on-demand when you've selected a tile\n",
    "6. **Visualization** - RGB composite, classification map, and false color views\n",
    "\n",
    "**Workflow:**\n",
    "1. Use the sliders in Section 5 to explore the image and select a tile\n",
    "2. When ready, execute Section 6 to run inference on the selected tile\n",
    "3. Execute Section 7 to visualize the results\n",
    "4. Return to Section 5 to select a new tile and repeat\n",
    "\n",
    "The model produces two probability outputs (water, cloud) which are thresholded at 0.5 to produce discrete classes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maji",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
