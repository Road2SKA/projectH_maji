{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-01-md-title",
   "metadata": {},
   "source": [
    "# Downloading Sentinel-2 Bands from Scratch\n",
    "\n",
    "This notebook reproduces what `maji.download` does, **step by step**,\n",
    "using only standard libraries.  No `maji` imports appear anywhere.\n",
    "\n",
    "**What you'll learn**\n",
    "\n",
    "1. How to authenticate with the CDSE S3-compatible API.\n",
    "2. How to read JP2 band files directly from S3 using rasterio.\n",
    "3. How to resample 20 m bands to 10 m resolution.\n",
    "4. How to stack multiple bands into a single Cloud-Optimized GeoTIFF.\n",
    "5. Retry strategies for transient network errors.\n",
    "\n",
    "**Libraries used**\n",
    "\n",
    "| Library | Role |\n",
    "|---------|------|\n",
    "| `rasterio` | Read JP2 from S3, write GeoTIFF |\n",
    "| `numpy` | Array manipulation |\n",
    "| `pystac_client` | Search STAC catalog (to get asset URLs) |\n",
    "| `geopandas` / `pandas` | Tabular data |\n",
    "| `matplotlib` | Visualise the downloaded bands |\n",
    "\n",
    "**Prerequisites**\n",
    "\n",
    "* The `maji` conda environment is active (`conda activate maji`).\n",
    "* You have CDSE S3 credentials (access key + secret key).  \n",
    "  Register free at [dataspace.copernicus.eu](https://dataspace.copernicus.eu/) and\n",
    "  generate credentials under *User Settings → S3 Access*.\n",
    "* Generate an access key at [https://eodata-s3keysmanager.dataspace.copernicus.eu/](https://eodata-s3keysmanager.dataspace.copernicus.eu/).\n",
    "* Save the key and secret in the `.env` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-02-imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from rasterio.enums import Resampling\n",
    "from rasterio.session import AWSSession\n",
    "from rasterio.transform import Affine\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(\"download_from_scratch\")\n",
    "\n",
    "# --- Constants (mirrors maji/download.py) ---\n",
    "\n",
    "# Bands we want to download\n",
    "MODEL_BANDS = [\"B03\", \"B04\", \"B08\", \"B8A\", \"B11\", \"B12\"]\n",
    "CLOUD_BAND = \"SCL\"\n",
    "ALL_BANDS = MODEL_BANDS + [CLOUD_BAND]\n",
    "\n",
    "# Native resolution of each Sentinel-2 band (metres)\n",
    "BAND_RESOLUTION: dict[str, int] = {\n",
    "    \"B02\": 10, \"B03\": 10, \"B04\": 10, \"B08\": 10,\n",
    "    \"B05\": 20, \"B06\": 20, \"B07\": 20, \"B8A\": 20,\n",
    "    \"B11\": 20, \"B12\": 20, \"SCL\": 20,\n",
    "    \"B01\": 60, \"B09\": 60,\n",
    "}\n",
    "\n",
    "# Full MGRS tile dimensions at 10 m resolution\n",
    "TARGET_HEIGHT = 10980\n",
    "TARGET_WIDTH = 10980\n",
    "\n",
    "# Retry configuration for transient S3 errors\n",
    "MAX_RETRIES = 3\n",
    "RETRY_BACKOFF = 2.0  # seconds, doubled each retry\n",
    "\n",
    "# CDSE concurrency limit\n",
    "_MAX_CDSE_WORKERS = 4\n",
    "\n",
    "print(\"Band configuration:\")\n",
    "print(f\"  Model bands : {MODEL_BANDS}\")\n",
    "print(f\"  Cloud band  : {CLOUD_BAND}\")\n",
    "print(f\"  Target size : {TARGET_WIDTH} x {TARGET_HEIGHT} pixels (10 m)\")\n",
    "\n",
    "# Load the credentials from the hidden file\n",
    "path_env_file = \"../.env\"\n",
    "success = load_dotenv(dotenv_path=path_env_file, override=True)\n",
    "if success: \n",
    "    print(f\"[INFO] Loaded environment from '{path_env_file}' file.\")\n",
    "    print(f\"\\tACCESS: {'CDSE_ACCESS_KEY' in os.environ}\")\n",
    "    print(f\"\\tSECRET: {'CDSE_SECRET_KEY' in os.environ}\")\n",
    "else:\n",
    "    print(f\"[ERROR] Failed to load environment from '{path_env_file}' file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-03-md-search",
   "metadata": {},
   "source": [
    "## §1 Load Search Results\n",
    "\n",
    "Instead of re-running the search, we load the results saved by\n",
    "`search_from_scratch.ipynb`. This avoids hitting the STAC API\n",
    "repeatedly and ensures both notebooks work with the same data.\n",
    "\n",
    "Run `search_from_scratch.ipynb` first if the files don't exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-04-search",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_DIR = Path(\"search_results\")\n",
    "\n",
    "# Load all scenes (for reference)\n",
    "scenes = gpd.read_parquet(RESULTS_DIR / \"scenes.parquet\")\n",
    "print(f\"Loaded {len(scenes)} scenes from {RESULTS_DIR / 'scenes.parquet'}\")\n",
    "\n",
    "# Load selected scene\n",
    "best_gdf = gpd.read_parquet(RESULTS_DIR / \"best_scene.parquet\")\n",
    "best_scene = best_gdf.iloc[0]\n",
    "\n",
    "print(f\"\\nSelected scene:\")\n",
    "print(f\"  ID       : {best_scene['scene_id']}\")\n",
    "print(f\"  Tile     : {best_scene['mgrs_tile']}\")\n",
    "print(f\"  Date     : {best_scene['datetime']}\")\n",
    "print(f\"  Coverage : {best_scene['coverage']:.1%}\")\n",
    "print(f\"  Cloud    : {best_scene['cloud_cover']:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-05-md-auth",
   "metadata": {},
   "source": [
    "## §2 S3 Authentication\n",
    "\n",
    "The CDSE eodata bucket uses an **S3-compatible API** but is hosted on\n",
    "Copernicus infrastructure, not AWS.  We need to configure rasterio's\n",
    "`AWSSession` with:\n",
    "\n",
    "1. **Access key** and **secret key** from your CDSE account.\n",
    "2. A custom **endpoint URL** pointing to CDSE: `https://eodata.dataspace.copernicus.eu`.\n",
    "3. `aws_unsigned=False` so that signed requests are sent.\n",
    "\n",
    "This mirrors `maji.download.create_s3_session()`.\n",
    "\n",
    "**Security note:** Never hard-code credentials.  Use environment variables\n",
    "or a secrets manager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-06-auth",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "def create_s3_session(\n",
    "    access_key: str,\n",
    "    secret_key: str,\n",
    "    endpoint_url: str = \"https://eodata.dataspace.copernicus.eu\",\n",
    "    region_name: str = \"default\",\n",
    ") -> AWSSession:\n",
    "    \"\"\"Create a rasterio AWSSession configured for CDSE S3.\n",
    "\n",
    "    Also sets GDAL environment variables for S3 access, which ensures\n",
    "    the credentials are available to all rasterio operations.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    access_key : str\n",
    "        S3 access key for the CDSE ``eodata`` bucket.\n",
    "    secret_key : str\n",
    "        Corresponding S3 secret key.\n",
    "    endpoint_url : str, optional\n",
    "        S3-compatible endpoint URL.\n",
    "    region_name : str, optional\n",
    "        AWS region (can be any value for non-AWS endpoints).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    rasterio.session.AWSSession\n",
    "        Configured session for use with rasterio.Env().\n",
    "    \"\"\"\n",
    "    # Set GDAL environment variables for S3 access\n",
    "    # These are read by GDAL's /vsis3/ driver\n",
    "    os.environ[\"AWS_ACCESS_KEY_ID\"] = access_key\n",
    "    os.environ[\"AWS_SECRET_ACCESS_KEY\"] = secret_key\n",
    "    os.environ[\"AWS_S3_ENDPOINT\"] = \"eodata.dataspace.copernicus.eu\"\n",
    "    os.environ[\"AWS_HTTPS\"] = \"YES\"\n",
    "    os.environ[\"AWS_VIRTUAL_HOSTING\"] = \"FALSE\"\n",
    "    os.environ[\"AWS_NO_SIGN_REQUEST\"] = \"NO\"\n",
    "    \n",
    "    # Create a boto3 session explicitly\n",
    "    boto_session = boto3.Session(\n",
    "        aws_access_key_id=access_key,\n",
    "        aws_secret_access_key=secret_key,\n",
    "        region_name=region_name,\n",
    "    )\n",
    "    \n",
    "    return AWSSession(\n",
    "        session=boto_session,\n",
    "        endpoint_url=endpoint_url,\n",
    "        aws_unsigned=False,\n",
    "    )\n",
    "\n",
    "\n",
    "# Load credentials from environment variables\n",
    "CDSE_ACCESS_KEY = os.environ.get(\"CDSE_ACCESS_KEY\", \"\")\n",
    "CDSE_SECRET_KEY = os.environ.get(\"CDSE_SECRET_KEY\", \"\")\n",
    "\n",
    "if not CDSE_ACCESS_KEY or not CDSE_SECRET_KEY:\n",
    "    print(\"WARNING: CDSE credentials not found in environment.\")\n",
    "    print(\"Set CDSE_ACCESS_KEY and CDSE_SECRET_KEY to download data.\")\n",
    "    print(\"\")\n",
    "    print(\"For this notebook, you can set them here (don't commit!):\")\n",
    "    print('  CDSE_ACCESS_KEY = \"your-access-key\"')\n",
    "    print('  CDSE_SECRET_KEY = \"your-secret-key\"')\n",
    "else:\n",
    "    print(f\"Credentials loaded: access_key={CDSE_ACCESS_KEY[:8]}...\")\n",
    "\n",
    "# Create the session (this also sets GDAL env vars)\n",
    "session = create_s3_session(CDSE_ACCESS_KEY, CDSE_SECRET_KEY)\n",
    "print(f\"Session endpoint: {session.endpoint_url}\")\n",
    "print(f\"GDAL S3 endpoint: {os.environ.get('AWS_S3_ENDPOINT', 'NOT SET')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kreu99l28pj",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test S3 connectivity with a simple file listing\n",
    "# This helps diagnose auth/endpoint issues before attempting downloads\n",
    "\n",
    "print(\"Testing S3 connectivity...\")\n",
    "print(f\"  Endpoint: {os.environ.get('AWS_S3_ENDPOINT')}\")\n",
    "print(f\"  Access key: {os.environ.get('AWS_ACCESS_KEY_ID', '')[:8]}...\")\n",
    "\n",
    "# Try listing a known bucket path using boto3\n",
    "try:\n",
    "    s3_client = boto3.client(\n",
    "        \"s3\",\n",
    "        aws_access_key_id=CDSE_ACCESS_KEY,\n",
    "        aws_secret_access_key=CDSE_SECRET_KEY,\n",
    "        endpoint_url=\"https://eodata.dataspace.copernicus.eu\",\n",
    "    )\n",
    "    # List a small portion of the Sentinel-2 prefix\n",
    "    response = s3_client.list_objects_v2(\n",
    "        Bucket=\"eodata\",\n",
    "        Prefix=\"Sentinel-2/MSI/L2A/2025/\",\n",
    "        MaxKeys=3,\n",
    "    )\n",
    "    if \"Contents\" in response:\n",
    "        print(f\"  ✓ S3 connection successful! Found {len(response['Contents'])} objects.\")\n",
    "        for obj in response[\"Contents\"][:3]:\n",
    "            print(f\"    - {obj['Key'][:60]}...\")\n",
    "    else:\n",
    "        print(\"  ⚠ Connected but no objects found at prefix.\")\n",
    "except Exception as e:\n",
    "    print(f\"  ✗ S3 connection failed: {e}\")\n",
    "    print(\"  Check your credentials and network connection.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qcc5ajk9ek",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the specific file exists on S3 before trying rasterio\n",
    "# This helps distinguish between \"auth failed\" vs \"file doesn't exist\"\n",
    "\n",
    "print(\"Checking if the scene files exist on S3...\")\n",
    "print()\n",
    "\n",
    "# Get the B03 asset URL\n",
    "test_href = best_scene[\"assets\"].get(\"B03\")\n",
    "print(f\"B03 asset URL: {test_href}\")\n",
    "print()\n",
    "\n",
    "if test_href:\n",
    "    # Parse the S3 path\n",
    "    # URL format: s3://eodata/Sentinel-2/MSI/L2A/...\n",
    "    s3_path = test_href.replace(\"s3://eodata/\", \"\")\n",
    "    \n",
    "    print(f\"Checking if file exists: {s3_path[:70]}...\")\n",
    "    \n",
    "    try:\n",
    "        s3_client = boto3.client(\n",
    "            \"s3\",\n",
    "            aws_access_key_id=CDSE_ACCESS_KEY,\n",
    "            aws_secret_access_key=CDSE_SECRET_KEY,\n",
    "            endpoint_url=\"https://eodata.dataspace.copernicus.eu\",\n",
    "        )\n",
    "        \n",
    "        # Try to get the object metadata (head_object)\n",
    "        response = s3_client.head_object(Bucket=\"eodata\", Key=s3_path)\n",
    "        print(f\"  ✓ File EXISTS!\")\n",
    "        print(f\"    Size: {response['ContentLength'] / 1e6:.1f} MB\")\n",
    "        print(f\"    Last modified: {response['LastModified']}\")\n",
    "        print()\n",
    "        print(\"The file exists - the issue is with GDAL/rasterio configuration.\")\n",
    "        \n",
    "    except s3_client.exceptions.ClientError as e:\n",
    "        error_code = e.response['Error']['Code']\n",
    "        if error_code == '404':\n",
    "            print(f\"  ✗ File NOT FOUND (404)\")\n",
    "            print()\n",
    "            print(\"The file doesn't exist on CDSE. This scene may have been:\")\n",
    "            print(\"  - Archived or moved\")\n",
    "            print(\"  - The asset URL in the STAC catalog is stale\")\n",
    "            print()\n",
    "            print(\"Try re-running the search notebook to get fresh scene URLs.\")\n",
    "        elif error_code == '403':\n",
    "            print(f\"  ✗ Access DENIED (403)\")\n",
    "            print(\"Your credentials don't have access to this file.\")\n",
    "        else:\n",
    "            print(f\"  ✗ Error: {error_code} - {e.response['Error']['Message']}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ Error checking file: {e}\")\n",
    "else:\n",
    "    print(\"No B03 asset found in scene\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eteq15flvn",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different GDAL virtual file system approaches\n",
    "# /vsis3/ sometimes has issues with non-AWS endpoints\n",
    "# Let's try /vsicurl/ with a signed URL instead\n",
    "\n",
    "from botocore.config import Config\n",
    "\n",
    "print(\"Testing alternative approaches to open the file with rasterio...\")\n",
    "print()\n",
    "\n",
    "test_href = best_scene[\"assets\"].get(\"B03\")\n",
    "s3_path = test_href.replace(\"s3://eodata/\", \"\")\n",
    "\n",
    "# Approach 1: Generate a presigned URL and use /vsicurl/\n",
    "print(\"Approach 1: Presigned URL with /vsicurl/\")\n",
    "try:\n",
    "    s3_client = boto3.client(\n",
    "        \"s3\",\n",
    "        aws_access_key_id=CDSE_ACCESS_KEY,\n",
    "        aws_secret_access_key=CDSE_SECRET_KEY,\n",
    "        endpoint_url=\"https://eodata.dataspace.copernicus.eu\",\n",
    "        config=Config(signature_version='s3v4'),\n",
    "    )\n",
    "    \n",
    "    presigned_url = s3_client.generate_presigned_url(\n",
    "        'get_object',\n",
    "        Params={'Bucket': 'eodata', 'Key': s3_path},\n",
    "        ExpiresIn=3600,  # 1 hour\n",
    "    )\n",
    "    print(f\"  Generated presigned URL: {presigned_url[:80]}...\")\n",
    "    \n",
    "    # Try opening with /vsicurl/\n",
    "    vsicurl_path = f\"/vsicurl/{presigned_url}\"\n",
    "    with rasterio.Env(GDAL_HTTP_UNSAFESSL=\"YES\", CPL_VSIL_CURL_ALLOWED_EXTENSIONS=\".jp2\"):\n",
    "        with rasterio.open(vsicurl_path) as src:\n",
    "            print(f\"  ✓ SUCCESS with presigned URL!\")\n",
    "            print(f\"    Image size: {src.width} x {src.height}\")\n",
    "            print(f\"    CRS: {src.crs}\")\n",
    "            PRESIGNED_URL_WORKS = True\n",
    "except Exception as e:\n",
    "    print(f\"  ✗ Failed: {e}\")\n",
    "    PRESIGNED_URL_WORKS = False\n",
    "\n",
    "print()\n",
    "\n",
    "# Approach 2: Try /vsis3/ with explicit GDAL config (one more time with force)\n",
    "print(\"Approach 2: /vsis3/ with GDAL config options\")\n",
    "try:\n",
    "    vsis3_path = test_href.replace(\"s3://\", \"/vsis3/\")\n",
    "    with rasterio.Env(\n",
    "        AWS_ACCESS_KEY_ID=CDSE_ACCESS_KEY,\n",
    "        AWS_SECRET_ACCESS_KEY=CDSE_SECRET_KEY,\n",
    "        AWS_S3_ENDPOINT=\"eodata.dataspace.copernicus.eu\",\n",
    "        AWS_HTTPS=\"YES\",\n",
    "        AWS_VIRTUAL_HOSTING=\"FALSE\",\n",
    "        CPL_VSIL_CURL_ALLOWED_EXTENSIONS=\".jp2\",\n",
    "    ):\n",
    "        with rasterio.open(vsis3_path) as src:\n",
    "            print(f\"  ✓ SUCCESS with /vsis3/!\")\n",
    "            print(f\"    Image size: {src.width} x {src.height}\")\n",
    "            VSIS3_WORKS = True\n",
    "except Exception as e:\n",
    "    print(f\"  ✗ Failed: {str(e)[:100]}\")\n",
    "    VSIS3_WORKS = False\n",
    "\n",
    "print()\n",
    "if PRESIGNED_URL_WORKS:\n",
    "    print(\"✓ PRESIGNED URLs work! We'll use this approach for downloads.\")\n",
    "elif VSIS3_WORKS:\n",
    "    print(\"✓ /vsis3/ works with explicit config!\")\n",
    "else:\n",
    "    print(\"✗ Neither approach worked. May need to download via boto3 first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-07-md-bands",
   "metadata": {},
   "source": [
    "## §3 Band Configuration\n",
    "\n",
    "Sentinel-2 bands have different native resolutions:\n",
    "\n",
    "| Resolution | Bands |\n",
    "|------------|-------|\n",
    "| 10 m | B02, B03, B04, B08 |\n",
    "| 20 m | B05, B06, B07, B8A, B11, B12, SCL |\n",
    "| 60 m | B01, B09 |\n",
    "\n",
    "For machine learning, we want all bands at the same resolution.\n",
    "We **resample 20 m bands to 10 m** using:\n",
    "\n",
    "* **Bilinear interpolation** for reflectance bands (smooth interpolation).\n",
    "* **Nearest-neighbour** for SCL (Scene Classification Layer) to preserve discrete class values.\n",
    "\n",
    "A full MGRS tile at 10 m is **10,980 x 10,980 pixels** (~110 km x 110 km)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-08-bands",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show which bands we'll download and their native resolutions\n",
    "print(\"Bands to download:\")\n",
    "print(f\"{'Band':6s} {'Resolution':12s} {'Resampling':12s}\")\n",
    "print(\"-\" * 32)\n",
    "for band in ALL_BANDS:\n",
    "    res = BAND_RESOLUTION.get(band, \"?\")\n",
    "    resample = \"none\" if res == 10 else (\"nearest\" if band == \"SCL\" else \"bilinear\")\n",
    "    print(f\"{band:6s} {str(res) + ' m':12s} {resample:12s}\")\n",
    "\n",
    "print(f\"\\nTarget output: {TARGET_WIDTH} x {TARGET_HEIGHT} pixels (10 m resolution)\")\n",
    "print(f\"Memory per band: {TARGET_WIDTH * TARGET_HEIGHT * 2 / 1e6:.1f} MB (uint16)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-09-md-retry",
   "metadata": {},
   "source": [
    "## §4 Reading Bands with Retry\n",
    "\n",
    "S3 reads can fail due to transient network issues.  The function below\n",
    "implements **exponential backoff retry**:\n",
    "\n",
    "1. Try to read the band.\n",
    "2. On `RasterioIOError`, wait `RETRY_BACKOFF * 2^attempt` seconds.\n",
    "3. Retry up to `MAX_RETRIES` times.\n",
    "4. If all attempts fail, raise a `RuntimeError`.\n",
    "\n",
    "The function also handles **resampling** in a single read operation—rasterio\n",
    "can resample on the fly using the `out_shape` parameter.\n",
    "\n",
    "This mirrors `maji.download._read_band_with_retry()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10-retry",
   "metadata": {},
   "outputs": [],
   "source": "import tempfile\nfrom tqdm.auto import tqdm\n\ndef read_band_with_retry(\n    href: str,\n    target_shape: tuple[int, int],\n    resampling: Resampling,\n    max_retries: int = MAX_RETRIES,\n    s3_client: \"boto3.client\" = None,\n    progress_bar: tqdm = None,\n) -> tuple[np.ndarray, dict]:\n    \"\"\"Read a single band from S3 with retry on transient errors.\n\n    Downloads the file via boto3 first (which handles CDSE auth correctly),\n    then opens it locally with rasterio.\n\n    Parameters\n    ----------\n    href : str\n        S3 path to the band file (e.g. ``s3://eodata/.../B03_10m.jp2``).\n    target_shape : tuple of int\n        ``(height, width)`` to resample to.\n    resampling : rasterio.enums.Resampling\n        Resampling method.\n    max_retries : int, optional\n        Number of retry attempts.\n    s3_client : boto3.client, optional\n        Pre-configured S3 client. If None, creates one using env vars.\n    progress_bar : tqdm, optional\n        Progress bar to update during download. If provided, the bar's\n        total will be set to the file size and updated as bytes transfer.\n\n    Returns\n    -------\n    data : numpy.ndarray\n        2-D uint16 array of shape ``target_shape``.\n    meta : dict\n        Contains ``crs``, ``transform``, and ``native_shape``.\n    \"\"\"\n    # Parse S3 path\n    # href format: s3://eodata/Sentinel-2/MSI/L2A/...\n    if href.startswith(\"s3://\"):\n        parts = href[5:].split(\"/\", 1)\n        bucket = parts[0]\n        key = parts[1]\n    else:\n        raise ValueError(f\"Expected s3:// URL, got: {href}\")\n\n    # Create S3 client if not provided\n    if s3_client is None:\n        s3_client = boto3.client(\n            \"s3\",\n            aws_access_key_id=os.environ.get(\"AWS_ACCESS_KEY_ID\", \"\"),\n            aws_secret_access_key=os.environ.get(\"AWS_SECRET_ACCESS_KEY\", \"\"),\n            endpoint_url=\"https://eodata.dataspace.copernicus.eu\",\n        )\n\n    last_error: Exception | None = None\n    \n    for attempt in range(max_retries):\n        try:\n            # Download to a temp file, then open with rasterio\n            with tempfile.NamedTemporaryFile(suffix=\".jp2\", delete=True) as tmp:\n                # Get file size for progress bar\n                if progress_bar is not None:\n                    head = s3_client.head_object(Bucket=bucket, Key=key)\n                    file_size = head['ContentLength']\n                    progress_bar.total = file_size\n                    progress_bar.refresh()\n                    \n                    # Track bytes for progress callback\n                    bytes_transferred = [0]\n                    \n                    def progress_callback(bytes_amount):\n                        bytes_transferred[0] += bytes_amount\n                        progress_bar.update(bytes_amount)\n                    \n                    logger.info(\"Downloading %s (%.1f MB)...\", key.split(\"/\")[-1], file_size / 1e6)\n                    s3_client.download_file(bucket, key, tmp.name, Callback=progress_callback)\n                else:\n                    logger.info(\"Downloading %s to temp file...\", key.split(\"/\")[-1])\n                    s3_client.download_file(bucket, key, tmp.name)\n                \n                with rasterio.open(tmp.name) as src:\n                    native_shape = (src.height, src.width)\n                    meta = {\n                        \"crs\": src.crs,\n                        \"transform\": src.transform,\n                        \"native_shape\": native_shape,\n                    }\n\n                    if native_shape == target_shape:\n                        # No resampling needed\n                        data = src.read(1)\n                    else:\n                        # Resample on the fly\n                        data = src.read(\n                            1,\n                            out_shape=target_shape,\n                            resampling=resampling,\n                        )\n\n                    return data, meta\n\n        except Exception as e:\n            last_error = e\n            wait = RETRY_BACKOFF * (2 ** attempt)\n            logger.warning(\n                \"S3 read failed for %s (attempt %d/%d), retrying in %.1fs: %s\",\n                href, attempt + 1, max_retries, wait, e,\n            )\n            # Reset progress bar on retry\n            if progress_bar is not None:\n                progress_bar.reset()\n            time.sleep(wait)\n\n    raise RuntimeError(\n        f\"Failed to read {href} after {max_retries} attempts\"\n    ) from last_error"
  },
  {
   "cell_type": "markdown",
   "id": "cell-11-md-download-tile",
   "metadata": {},
   "source": [
    "## §5 Download a Single Tile\n",
    "\n",
    "The `download_tile()` function orchestrates the full download:\n",
    "\n",
    "1. **Set up output path** — `data_dir / mgrs_tile / YYYY-MM-DD_S2L2A.tif`.\n",
    "2. **Skip if exists** — unless `overwrite=True`.\n",
    "3. **Get CRS/transform** — read a 10 m band to get the native coordinate system.\n",
    "4. **Read and write each band** — one at a time to keep memory low.\n",
    "5. **Write Cloud-Optimized GeoTIFF** — deflate compression, 512×512 internal tiles.\n",
    "\n",
    "The rasterio environment is configured with:\n",
    "* `AWS_VIRTUAL_HOSTING=False` — use path-style URLs (required for CDSE).\n",
    "* `GDAL_DISABLE_READDIR_ON_OPEN=\"TRUE\"` — avoid listing the directory (faster).\n",
    "* `CPL_VSIL_CURL_ALLOWED_EXTENSIONS=\".jp2\"` — restrict to JP2 files.\n",
    "\n",
    "This mirrors `maji.download.download_tile()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12-download-tile",
   "metadata": {},
   "outputs": [],
   "source": "def download_tile(\n    scene_assets: dict[str, str],\n    mgrs_tile: str,\n    scene_date: str,\n    data_dir: Path,\n    session: AWSSession = None,  # Kept for API compatibility, not used\n    bands: list[str] | None = None,\n    overwrite: bool = False,\n) -> Path:\n    \"\"\"Download all bands for one scene and write a multi-band GeoTIFF.\n\n    Downloads files via boto3 (which works with CDSE), then processes\n    with rasterio locally. Shows progress bars for each band download.\n\n    Parameters\n    ----------\n    scene_assets : dict[str, str]\n        ``{band_name: s3_href}`` mapping from search results.\n    mgrs_tile : str\n        Five-character MGRS tile code.\n    scene_date : str\n        ISO date string (used in output filename).\n    data_dir : Path\n        Root data directory.\n    session : rasterio.session.AWSSession, optional\n        Kept for API compatibility. Not used (boto3 handles auth).\n    bands : list[str] or None, optional\n        Bands to download (default: ALL_BANDS).\n    overwrite : bool, optional\n        Re-download existing files.\n\n    Returns\n    -------\n    pathlib.Path\n        Path to the saved GeoTIFF.\n    \"\"\"\n    if bands is None:\n        bands = list(ALL_BANDS)\n\n    # Output path\n    tile_dir = data_dir / mgrs_tile\n    tile_dir.mkdir(parents=True, exist_ok=True)\n    out_path = tile_dir / f\"{scene_date}_S2L2A.tif\"\n\n    if out_path.exists() and not overwrite:\n        logger.info(\"Skipping %s (already exists)\", out_path)\n        return out_path\n\n    # Create S3 client for downloads\n    s3_client = boto3.client(\n        \"s3\",\n        aws_access_key_id=CDSE_ACCESS_KEY,\n        aws_secret_access_key=CDSE_SECRET_KEY,\n        endpoint_url=\"https://eodata.dataspace.copernicus.eu\",\n    )\n\n    target_shape = (TARGET_HEIGHT, TARGET_WIDTH)\n    reference_crs = None\n    reference_transform = None\n\n    # Read first 10m band to get CRS/transform (no progress bar for this initial read)\n    for band_name in bands:\n        if BAND_RESOLUTION.get(band_name) == 10:\n            href = scene_assets.get(band_name)\n            if href is None:\n                continue\n            _, meta = read_band_with_retry(\n                href, target_shape, Resampling.bilinear, s3_client=s3_client,\n            )\n            if meta[\"native_shape\"] == target_shape:\n                reference_crs = meta[\"crs\"]\n                reference_transform = meta[\"transform\"]\n                break\n\n    # Fallback: derive 10m transform from a 20m band\n    if reference_crs is None:\n        first_href = scene_assets[bands[0]]\n        _, meta = read_band_with_retry(\n            first_href, target_shape, Resampling.bilinear, s3_client=s3_client,\n        )\n        reference_crs = meta[\"crs\"]\n        t = meta[\"transform\"]\n        native_h, native_w = meta[\"native_shape\"]\n        scale = native_h / TARGET_HEIGHT\n        reference_transform = Affine(\n            t.a * scale, t.b, t.c,\n            t.d, t.e * scale, t.f,\n        )\n\n    # Cloud-Optimized GeoTIFF profile\n    profile = {\n        \"driver\": \"GTiff\",\n        \"dtype\": \"uint16\",\n        \"width\": TARGET_WIDTH,\n        \"height\": TARGET_HEIGHT,\n        \"count\": len(bands),\n        \"crs\": reference_crs,\n        \"transform\": reference_transform,\n        \"compress\": \"deflate\",\n        \"tiled\": True,\n        \"blockxsize\": 512,\n        \"blockysize\": 512,\n    }\n\n    total_bytes = 0\n    \n    with rasterio.open(out_path, \"w\", **profile) as dst:\n        # Overall band progress bar\n        band_pbar = tqdm(\n            enumerate(bands, start=1),\n            total=len(bands),\n            desc=\"Downloading bands\",\n            unit=\"band\",\n        )\n        \n        for band_idx, band_name in band_pbar:\n            href = scene_assets.get(band_name)\n            if href is None:\n                raise KeyError(\n                    f\"No S3 href found for band {band_name} in scene assets\"\n                )\n\n            resampling = (\n                Resampling.nearest if band_name == \"SCL\"\n                else Resampling.bilinear\n            )\n\n            native_res = BAND_RESOLUTION.get(band_name, 0)\n            band_pbar.set_postfix(band=band_name, res=f\"{native_res}m\")\n\n            # Per-file progress bar for download\n            with tqdm(\n                unit='B',\n                unit_scale=True,\n                unit_divisor=1024,\n                desc=f\"  {band_name}\",\n                leave=False,\n            ) as file_pbar:\n                data, _ = read_band_with_retry(\n                    href, target_shape, resampling, s3_client=s3_client,\n                    progress_bar=file_pbar,\n                )\n                total_bytes += file_pbar.n\n            \n            dst.write(data, band_idx)\n            dst.set_band_description(band_idx, band_name)\n\n    size_mb = out_path.stat().st_size / 1e6\n    logger.info(\n        \"Saved %s (%d bands, %.1f MB downloaded, %.1f MB on disk)\",\n        out_path, len(bands), total_bytes / 1e6, size_mb,\n    )\n    return out_path"
  },
  {
   "cell_type": "markdown",
   "id": "cell-13-md-download-tiles",
   "metadata": {},
   "source": [
    "## §6 Download Multiple Tiles\n",
    "\n",
    "The `download_tiles()` function iterates over a DataFrame of scenes\n",
    "and calls `download_tile()` for each one.\n",
    "\n",
    "**CDSE concurrency limit:** CDSE allows a maximum of **4 concurrent S3 connections**\n",
    "per credential set.  The function clamps `max_workers` to this limit and\n",
    "issues a warning if you try to exceed it.\n",
    "\n",
    "Failures are logged but do not halt the loop—this lets you download\n",
    "as many tiles as possible even if some fail.\n",
    "\n",
    "This mirrors `maji.download.download_tiles()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14-download-tiles",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_tiles(\n",
    "    scenes: pd.DataFrame,\n",
    "    data_dir: Path,\n",
    "    session: AWSSession,\n",
    "    bands: list[str] | None = None,\n",
    "    max_workers: int = 1,\n",
    "    overwrite: bool = False,\n",
    ") -> list[Path]:\n",
    "    \"\"\"Download multiple scenes sequentially.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    scenes : pandas.DataFrame\n",
    "        DataFrame with ``mgrs_tile``, ``datetime``, and ``assets`` columns.\n",
    "    data_dir : Path\n",
    "        Root data directory.\n",
    "    session : rasterio.session.AWSSession\n",
    "        Authenticated session.\n",
    "    bands : list[str] or None, optional\n",
    "        Bands to download.\n",
    "    max_workers : int, optional\n",
    "        Reserved for future parallel downloads.\n",
    "    overwrite : bool, optional\n",
    "        Re-download existing files.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list[pathlib.Path]\n",
    "        Paths to successfully saved GeoTIFFs.\n",
    "    \"\"\"\n",
    "    if max_workers > _MAX_CDSE_WORKERS:\n",
    "        warnings.warn(\n",
    "            f\"max_workers={max_workers} exceeds CDSE limit of \"\n",
    "            f\"{_MAX_CDSE_WORKERS} concurrent connections; clamping to \"\n",
    "            f\"{_MAX_CDSE_WORKERS}\",\n",
    "            stacklevel=2,\n",
    "        )\n",
    "        max_workers = _MAX_CDSE_WORKERS\n",
    "\n",
    "    paths: list[Path] = []\n",
    "    for _, row in scenes.iterrows():\n",
    "        scene_date = row[\"datetime\"].strftime(\"%Y-%m-%d\")\n",
    "        try:\n",
    "            path = download_tile(\n",
    "                scene_assets=row[\"assets\"],\n",
    "                mgrs_tile=row[\"mgrs_tile\"],\n",
    "                scene_date=scene_date,\n",
    "                data_dir=Path(data_dir),\n",
    "                session=session,\n",
    "                bands=bands,\n",
    "                overwrite=overwrite,\n",
    "            )\n",
    "            paths.append(path)\n",
    "        except Exception:\n",
    "            logger.error(\n",
    "                \"Failed to download %s/%s\",\n",
    "                row[\"mgrs_tile\"], scene_date,\n",
    "                exc_info=True,\n",
    "            )\n",
    "\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15-md-run-download",
   "metadata": {},
   "source": [
    "## §7 Run the Download\n",
    "\n",
    "Now let's download the scene we selected earlier.\n",
    "\n",
    "**Note:** This cell will fail if you haven't set your CDSE credentials.\n",
    "Set `CDSE_S3_ACCESS_KEY` and `CDSE_S3_SECRET_KEY` environment variables,\n",
    "or uncomment the lines below to set them directly (don't commit!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16-run-download",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and fill in your credentials if not using environment variables:\n",
    "# CDSE_ACCESS_KEY = \"your-access-key\"\n",
    "# CDSE_SECRET_KEY = \"your-secret-key\"\n",
    "# session = create_s3_session(CDSE_ACCESS_KEY, CDSE_SECRET_KEY)\n",
    "\n",
    "# Output directory (relative to notebook)\n",
    "DATA_DIR = Path(\"../data\")\n",
    "\n",
    "# Download the best scene\n",
    "scene_date = best_scene[\"datetime\"].strftime(\"%Y-%m-%d\")\n",
    "\n",
    "print(f\"Downloading scene: {best_scene['scene_id']}\")\n",
    "print(f\"  Tile: {best_scene['mgrs_tile']}\")\n",
    "print(f\"  Date: {scene_date}\")\n",
    "print(f\"  Bands: {ALL_BANDS}\")\n",
    "print(f\"  Output: {DATA_DIR / best_scene['mgrs_tile']}\")\n",
    "print()\n",
    "\n",
    "out_path = download_tile(\n",
    "    scene_assets=best_scene[\"assets\"],\n",
    "    mgrs_tile=best_scene[\"mgrs_tile\"],\n",
    "    scene_date=scene_date,\n",
    "    data_dir=DATA_DIR,\n",
    "    session=session,\n",
    "    bands=ALL_BANDS,\n",
    "    overwrite=False,\n",
    ")\n",
    "\n",
    "print(f\"\\nDownload complete: {out_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17-md-inspect",
   "metadata": {},
   "source": [
    "## §8 Inspect the Output\n",
    "\n",
    "Let's verify the downloaded GeoTIFF has the expected structure:\n",
    "7 bands, 10,980 x 10,980 pixels, correct CRS, and band descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18-inspect",
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(out_path) as src:\n",
    "    print(f\"File: {out_path.name}\")\n",
    "    print(f\"Size: {out_path.stat().st_size / 1e6:.1f} MB\")\n",
    "    print(f\"\")\n",
    "    print(f\"Dimensions: {src.width} x {src.height} pixels\")\n",
    "    print(f\"Bands: {src.count}\")\n",
    "    print(f\"CRS: {src.crs}\")\n",
    "    print(f\"Transform: {src.transform}\")\n",
    "    print(f\"Dtype: {src.dtypes[0]}\")\n",
    "    print(f\"\")\n",
    "    print(\"Band descriptions:\")\n",
    "    for i in range(1, src.count + 1):\n",
    "        desc = src.descriptions[i - 1] or f\"Band {i}\"\n",
    "        print(f\"  {i}: {desc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19-md-visualise",
   "metadata": {},
   "source": [
    "## §9 Visualise the Bands\n",
    "\n",
    "Let's create a quick RGB composite and show all bands as a grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20-visualise",
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(out_path) as src:\n",
    "    # Read all bands (subsample for display)\n",
    "    step = 10  # Read every 10th pixel\n",
    "    bands_data = src.read(\n",
    "        out_shape=(src.count, src.height // step, src.width // step),\n",
    "        resampling=Resampling.nearest,\n",
    "    )\n",
    "    band_names = [src.descriptions[i] or f\"Band {i+1}\" for i in range(src.count)]\n",
    "\n",
    "# Create figure with subplots\n",
    "n_bands = len(band_names)\n",
    "n_cols = 4\n",
    "n_rows = (n_bands + n_cols - 1) // n_cols\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(14, n_rows * 3.5))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (data, name) in enumerate(zip(bands_data, band_names)):\n",
    "    ax = axes[i]\n",
    "    # Clip to 2nd-98th percentile for better contrast\n",
    "    vmin, vmax = np.percentile(data[data > 0], [2, 98])\n",
    "    ax.imshow(data, cmap=\"viridis\", vmin=vmin, vmax=vmax)\n",
    "    ax.set_title(name)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "# Hide empty subplots\n",
    "for i in range(n_bands, len(axes)):\n",
    "    axes[i].axis(\"off\")\n",
    "\n",
    "plt.suptitle(f\"Downloaded Bands \\u2014 Tile {best_scene['mgrs_tile']} ({scene_date})\", y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21-rgb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create true-color RGB composite (B04=Red, B03=Green, B02 not available, use B03)\n",
    "# Since we have B03 and B04, let's make a false-color composite:\n",
    "# NIR-Red-Green (B08, B04, B03) - vegetation appears red\n",
    "\n",
    "with rasterio.open(out_path) as src:\n",
    "    # Find band indices\n",
    "    band_idx = {src.descriptions[i]: i + 1 for i in range(src.count)}\n",
    "    \n",
    "    # Read at reduced resolution for display\n",
    "    step = 10\n",
    "    out_shape = (src.height // step, src.width // step)\n",
    "    \n",
    "    b08 = src.read(band_idx[\"B08\"], out_shape=out_shape, resampling=Resampling.nearest)\n",
    "    b04 = src.read(band_idx[\"B04\"], out_shape=out_shape, resampling=Resampling.nearest)\n",
    "    b03 = src.read(band_idx[\"B03\"], out_shape=out_shape, resampling=Resampling.nearest)\n",
    "\n",
    "def normalize_band(band, pmin=2, pmax=98):\n",
    "    \"\"\"Normalize band to 0-1 using percentile clipping.\"\"\"\n",
    "    valid = band[band > 0]\n",
    "    if len(valid) == 0:\n",
    "        return np.zeros_like(band, dtype=np.float32)\n",
    "    vmin, vmax = np.percentile(valid, [pmin, pmax])\n",
    "    clipped = np.clip(band, vmin, vmax)\n",
    "    return (clipped - vmin) / (vmax - vmin)\n",
    "\n",
    "# Stack as RGB\n",
    "rgb = np.dstack([\n",
    "    normalize_band(b08),  # NIR -> Red channel\n",
    "    normalize_band(b04),  # Red -> Green channel\n",
    "    normalize_band(b03),  # Green -> Blue channel\n",
    "])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.imshow(rgb)\n",
    "ax.set_title(f\"False-Color Composite (NIR-Red-Green)\\nTile {best_scene['mgrs_tile']} ({scene_date})\")\n",
    "ax.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Vegetation appears in shades of red/orange.\")\n",
    "print(\"Bare soil/rock appears in brown/beige.\")\n",
    "print(\"Water appears dark blue/black.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22-md-wrapup",
   "metadata": {},
   "source": [
    "## Wrap-up & Key Takeaways\n",
    "\n",
    "This notebook walked through every step that `maji.download` performs:\n",
    "\n",
    "1. **S3 session creation** — configure rasterio for CDSE's S3-compatible endpoint.\n",
    "2. **Band configuration** — understand native resolutions and resampling strategies.\n",
    "3. **Retry logic** — exponential backoff for transient network errors.\n",
    "4. **Tile download** — read bands one at a time, resample 20m→10m, write COG.\n",
    "5. **Batch download** — iterate over scenes, handle failures gracefully.\n",
    "\n",
    "In production, use the packaged module instead of re-implementing these steps:\n",
    "\n",
    "```python\n",
    "from maji.search import search_scenes, select_best_scenes\n",
    "from maji.download import create_s3_session, download_tiles\n",
    "\n",
    "scenes = search_scenes(bbox=BBOX, start=START, end=END)\n",
    "best = select_best_scenes(scenes, strategy=\"least_cloudy\")\n",
    "\n",
    "session = create_s3_session(access_key, secret_key)\n",
    "paths = download_tiles(best, data_dir=Path(\"data\"), session=session)\n",
    "```\n",
    "\n",
    "**Key points**\n",
    "\n",
    "* CDSE uses an **S3-compatible API** with path-style URLs (not AWS virtual hosting).\n",
    "* Resampling happens on the fly via `rasterio.read(out_shape=...)`.\n",
    "* **SCL uses nearest-neighbour** resampling to preserve classification values.\n",
    "* Output is a **Cloud-Optimized GeoTIFF** with internal tiling and compression.\n",
    "* CDSE limits you to **4 concurrent connections** per credential set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maji",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}